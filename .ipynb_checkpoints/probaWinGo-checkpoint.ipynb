{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VmQVN0PrvFik"
   },
   "source": [
    "# Train an heuristic to play Go\n",
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/Jeremynadal33/GameGo/blob/master/probaWinGo.ipynb)This notebook trains & compare DL models to predict a probability to win a game of GO from a given set of already played moves. \n",
    "\n",
    "The work in this notebook is based on [L. Simon's file](https://nbviewer.jupyter.org/urls/www.labri.fr/perso/lsimon/IA-M1/TP-Note-ML-GO.ipynb)\n",
    "\n",
    "## First, let's import the database\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "gd0eF6HkxQHf",
    "outputId": "0946d5c0-fcfc-4adc-9a5f-bcaedb8a6dfd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.4.0\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "import tensorflow as tf\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ozv20eWBvFiq",
    "outputId": "75f058a3-4f26-490a-87ee-52edc44bb7da"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We have 41563 examples with the scores to train, ...\n",
      "We have 1000 examples to score (but for which we don't know the real values)\n"
     ]
    }
   ],
   "source": [
    "def get_raw_data_go(file):\n",
    "    ''' Returns the set of samples from the local file or download it if it does not exists'''\n",
    "    import gzip, os.path\n",
    "    import json\n",
    "\n",
    "    if not os.path.isfile(file):\n",
    "        print(\"File\", file, \"not found, I am downloading it...\\n\", end=\"\")\n",
    "        import urllib.request \n",
    "        urllib.request.urlretrieve (\"https://www.labri.fr/perso/lsimon/IA-M1/\" + file, file)\n",
    "        print(\" Done\")\n",
    "\n",
    "    with gzip.open(file) as fz:\n",
    "        data = json.loads(fz.read().decode(\"utf-8\"))\n",
    "    return data\n",
    "\n",
    "file = \"samples-9x9.json.gz\"\n",
    "file_evaluate = \"positions-to-evaluate-9x9.json.gz\"\n",
    "data = get_raw_data_go(file)\n",
    "data_to_evaluate = get_raw_data_go(file_evaluate)\n",
    "\n",
    "print(\"We have\", len(data),\"examples with the scores to train, ...\")\n",
    "print(\"We have\", len(data_to_evaluate),\"examples to score (but for which we don't know the real values)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "N99O8dLXvFir"
   },
   "source": [
    "## Then, let's explore each entry\n",
    "### First on the data set with results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "HFaNImqJvFis",
    "outputId": "f19329a4-9135-4c91-cded-c6da7ad2cf40"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample 10 \n",
      "\n",
      "Données brutes en format JSON: {'depth': 8, 'list_of_moves': ['C6', 'E7', 'C3', 'C8', 'E5', 'G3', 'B7', 'H7'], 'black_stones': ['B7', 'C6', 'E5', 'C3'], 'white_stones': ['C8', 'E7', 'H7', 'G3'], 'rollouts': 100, 'black_wins': 60, 'black_points': 876.0, 'white_wins': 40, 'white_points': 378.0} \n",
      "\n",
      "The sample was obtained after 8 moves\n",
      "The successive moves were ['C6', 'E7', 'C3', 'C8', 'E5', 'G3', 'B7', 'H7']\n",
      "After these moves and all the captures, there was black stones at the following position ['B7', 'C6', 'E5', 'C3']\n",
      "After these moves and all the captures, there was white stones at the following position ['C8', 'E7', 'H7', 'G3']\n",
      "Number of rollouts (gnugo games played against itself from this position): 100\n",
      "Over these 100 games, black won 60 times with 876.0 total points over all this winning games\n",
      "Over these 100 games, white won 40 times with 378.0 total points over all this winning games\n"
     ]
    }
   ],
   "source": [
    "def summary_of_example(data, sample_nb):\n",
    "    ''' Gives you some insights about a sample number'''\n",
    "    sample = data[sample_nb]\n",
    "    print(\"Sample\", sample_nb,'\\n')\n",
    "    print(\"Données brutes en format JSON:\", sample, '\\n')\n",
    "    print(\"The sample was obtained after\", sample[\"depth\"], \"moves\")\n",
    "    print(\"The successive moves were\", sample[\"list_of_moves\"])\n",
    "    print(\"After these moves and all the captures, there was black stones at the following position\", sample[\"black_stones\"])\n",
    "    print(\"After these moves and all the captures, there was white stones at the following position\", sample[\"white_stones\"])\n",
    "    print(\"Number of rollouts (gnugo games played against itself from this position):\", sample[\"rollouts\"])\n",
    "    print(\"Over these\", sample[\"rollouts\"], \"games, black won\", sample[\"black_wins\"], \"times with\", sample[\"black_points\"], \"total points over all this winning games\")\n",
    "    print(\"Over these\", sample[\"rollouts\"], \"games, white won\", sample[\"white_wins\"], \"times with\", sample[\"white_points\"], \"total points over all this winning games\")\n",
    "\n",
    "    \n",
    "summary_of_example(data,10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IN4MgDCmvFit"
   },
   "source": [
    "### On the data to evaluate, there is less information : "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "StrAXim-vFit",
    "outputId": "fb70c521-917d-4b9b-8232-d7529a3eaeba"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'depth': 16, 'list_of_moves': ['E6', 'E3', 'C3', 'G6', 'G7', 'C6', 'H7', 'H4', 'D2', 'F6', 'E8', 'C8', 'E5', 'B9', 'E7', 'E2'], 'black_stones': ['E8', 'E7', 'G7', 'H7', 'E6', 'E5', 'C3', 'D2'], 'white_stones': ['B9', 'C8', 'C6', 'F6', 'G6', 'H4', 'E3'], 'rollouts': 100}\n"
     ]
    }
   ],
   "source": [
    "print(data_to_evaluate[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dgSGWW5CvFiu"
   },
   "source": [
    "## Let's try to get a deeper understanding of the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "-13N7oxmvFiv"
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'pandas'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-17-6fc447902214>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpyplot\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mpandas\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mseaborn\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0msns\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'pandas'"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "3pA8x_shvFiw",
    "outputId": "00e493c1-a65d-4363-f526-8809765b76db"
   },
   "outputs": [],
   "source": [
    "df_data = pd.read_json(file)\n",
    "df_data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 297
    },
    "id": "-I5Htk0-vFix",
    "outputId": "96c4b033-439e-4d40-aa04-67d39bc8e84b"
   },
   "outputs": [],
   "source": [
    "df_data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 560
    },
    "id": "A_O9MZGsvFiy",
    "outputId": "efbe996a-88a2-4bac-eacc-0c3cff2786b1"
   },
   "outputs": [],
   "source": [
    "def corr_threshold(df,thresh, root_dir=''):\n",
    "    import seaborn as sns\n",
    "    upper = df.corr().where(np.triu(np.ones(df.corr().shape), k=1).astype(np.bool)).abs()\n",
    "    upper = upper[upper>=thresh]\n",
    "    \n",
    "    plt.figure(figsize=(10,5))\n",
    "    hm = sns.heatmap(upper, cmap=\"coolwarm\")\n",
    "    hm.set_xticklabels(hm.get_xticklabels(), rotation=90,fontsize=10)\n",
    "    hm.set_yticklabels(hm.get_yticklabels(), rotation=0,fontsize=10) \n",
    "\n",
    "    plt.savefig(root_dir+'corr_heat.png',transparent=True)\n",
    "    plt.show()\n",
    "    \n",
    "    upper = upper.stack().sort_values(ascending=False)\n",
    "    upper = pd.DataFrame(upper).reset_index()\n",
    "    upper.columns = ['Var 1', 'Var 2', 'correlation']\n",
    "    \n",
    "    index =  np.max([ i for i in range(len(upper['correlation'])) if upper['correlation'][i]>=thresh])\n",
    "    return upper[:index+1]\n",
    "\n",
    "corr_threshold(df_data, 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 312
    },
    "id": "Q8pz1kn6vFiz",
    "outputId": "69441e40-4922-49e3-89d1-852b06865fe9"
   },
   "outputs": [],
   "source": [
    "# Cumulative Distribution function of the chance of black to win\n",
    "cdf_wins = sorted([sample[\"black_wins\"] for sample in data])\n",
    "plt.figure()\n",
    "plt.plot([x/len(cdf_wins) for x in range(len(cdf_wins))], cdf_wins)\n",
    "plt.title(\"Cumulative Distribution function of the chance of black to win\")\n",
    "plt.xlabel(\"\\% of the samples with a chance of black to win below y\")\n",
    "plt.ylabel(\"Chance of black to win\")\n",
    "print(\"The CDF curve shows that black has more chances to win, globally\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7kLW6tgsvFi0"
   },
   "outputs": [],
   "source": [
    "df_data['range_game'] = 'Beginning'\n",
    "\n",
    "df_data.loc[df_data['depth']>17,'range_game'] = 'Middle'\n",
    "df_data.loc[df_data['depth']>41,'range_game'] = 'End'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 297
    },
    "id": "XwHd7JV4vFi1",
    "outputId": "ea9a8fce-30b4-4741-d438-94810acfe5c2"
   },
   "outputs": [],
   "source": [
    "sns.scatterplot(x='black_wins', y='black_points', \n",
    "                hue='range_game', data=df_data ) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "4hBk-kHCvFi2",
    "outputId": "f8c56f55-7adb-4dfe-e545-9fc373f52d4a"
   },
   "outputs": [],
   "source": [
    "df_data.groupby(\"range_game\").describe().transpose()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ANjMxs8-vFi3"
   },
   "source": [
    "## Information from the dataset of train :\n",
    "* There is 41563 games \n",
    "* There is almost 65 % of games won by the player black -> hidden bias ? \n",
    "* A given board is awarded a certain number of points as well as the winning porbability\n",
    "* The score of the board and the probability of winning are highly correlated\n",
    "* The depth of the game seems important to predict the probability of winning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fmsi3i7qvFi4"
   },
   "source": [
    "## Let's transform the input data into numpy arrays to feed the NN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qnTYygcIvFi5"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def name_to_coord(s):\n",
    "    assert s != \"PASS\"\n",
    "    indexLetters = {'A':0, 'B':1, 'C':2, 'D':3, 'E':4, 'F':5, 'G':6, 'H':7, 'J':8}\n",
    "\n",
    "    col = indexLetters[s[0]]\n",
    "    lin = int(s[1:]) - 1\n",
    "    return col, lin\n",
    "\n",
    " # Vous pouvez utiliser votre propre fonction ici si vous voulez utiliser un autre encodage\n",
    "def json_to_numpy(sample):\n",
    "    to_return = np.zeros((9,9,2))\n",
    "    indices = [\"black_stones\", \"white_stones\"]\n",
    "    for plane, name in enumerate(indices):\n",
    "        for coord_name in sample[name]:\n",
    "            x, y = name_to_coord(coord_name)\n",
    "            to_return[x,y,plane] = 1\n",
    "    return to_return\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "N_JavehcvFi7",
    "outputId": "25645579-d2ad-4f33-9817-943aee69cc41"
   },
   "outputs": [],
   "source": [
    "samp = 10\n",
    "print('For sample ', samp)\n",
    "print(data[samp])\n",
    "encoded = json_to_numpy(data[samp])\n",
    "\n",
    "print(\"_________________________\\nEncoded shape is\")\n",
    "print(encoded.shape)\n",
    "print(\"The first dimension contains the positioning of the black pieces\")\n",
    "print(encoded[:,:,0])\n",
    "print(\"Black pieces with positions: \", data[10][\"black_stones\"],'\\n')\n",
    "print(\"The second dimension contains the positioning of the white pieces\")\n",
    "print(encoded[:,:,1])\n",
    "print(\"White pieces with positions \", data[10][\"white_stones\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fpTXLoOSvFi8"
   },
   "source": [
    "## We will train a model that predicts the probability of winning \n",
    "To make things easier, we will build a pipeline that processes the json entry, modify it into a numpy array and predicts ***the probability of chance for the black player to win***. \n",
    "\n",
    "To begin with, let's implement a convolutional based NN that process ***only the two sets of boards*** as a whole information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "R1_5drlSvFi8"
   },
   "outputs": [],
   "source": [
    "def get_dataset(data, random_state = 42, test_size = 0.33) : \n",
    "  X = []\n",
    "  y = []\n",
    "  for d in data:\n",
    "    X.append(json_to_numpy(d))\n",
    "    y.append(d[\"black_wins\"] / d[\"rollouts\"])\n",
    "\n",
    "  X = np.array(X)\n",
    "  y = np.array(y)\n",
    "  X_train, X_test, y_train, y_test = train_test_split(X, y, test_size= test_size, random_state= random_state)\n",
    "  print('Each entry is of shape : {}\\nThere is {} samples in the train set and {} in the test'.format( X_train[0].shape, X_train.shape[0], X_test.shape[0] ))\n",
    "  print('Here is a sample : \\nX[0] :',X_train[0][0] , '\\nX[1] :', X_train[0][1] , '\\n y :',y_train[0])\n",
    "  return X_train, X_test, y_train, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "RNYtYpbhvd4i",
    "outputId": "597c71d6-bc63-48a5-fdd4-4c0585994384"
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = get_dataset(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "zweg1px0yje8",
    "outputId": "5c0bdc05-2b02-47db-f75b-dac8e2fa17aa"
   },
   "outputs": [],
   "source": [
    "model = tf.keras.models.Sequential()\n",
    "model.add(tf.keras.layers.InputLayer(input_shape=(9,9,2)))\n",
    "model.add(tf.keras.layers.Conv2D(filters=16,kernel_size=3,padding='same'))\n",
    "model.add(tf.keras.layers.Conv2D(filters=16,kernel_size=3,padding='same'))\n",
    "model.add(tf.keras.layers.Dense(15, activation='sigmoid', kernel_initializer='normal')) #64 = neurone, kernel_n\n",
    "model.add(tf.keras.layers.Dense(15, activation='sigmoid', kernel_initializer='normal')) #64 = neurone, kernel_n\n",
    "\n",
    "model.add(tf.keras.layers.Flatten())\n",
    "model.add(tf.keras.layers.Dense(1,activation='sigmoid'))\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6Zu2fMiEzex3",
    "outputId": "4ad4d611-b64f-4faf-b61b-ff5622c6dc58"
   },
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam',loss=tf.keras.losses.MeanSquaredError())\n",
    "\n",
    "\n",
    "callbacks = tf.keras.callbacks.EarlyStopping(monitor='val_loss',patience = 20)\n",
    "\n",
    "history = model.fit(X_train, y_train, \n",
    "                    validation_data = (X_test, y_test), \n",
    "\n",
    "                    callbacks = callbacks, \n",
    "                    epochs=80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 295
    },
    "id": "C4hD-eAl05C8",
    "outputId": "8c54744b-0035-4fea-af3c-d1693df445f5"
   },
   "outputs": [],
   "source": [
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'val'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "TymgCc_QGm5x",
    "outputId": "46f87d90-c6fe-4066-80d5-eb69d8c8ca37"
   },
   "outputs": [],
   "source": [
    "samp = 5\n",
    "\n",
    "model.predict(X_test[samp:samp+5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "StESLyv4JOp2",
    "outputId": "b7b5fe50-d4e0-4c85-b41a-9a4c97c8cc85"
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'y_test' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-18-5c09afa57168>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0my_test\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0msamp\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0msamp\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'y_test' is not defined"
     ]
    }
   ],
   "source": [
    "y_test[samp:samp+5]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "name": "probaWinGo.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
