{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VmQVN0PrvFik"
   },
   "source": [
    "# Train an heuristic to play Go\n",
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/Jeremynadal33/GameGo/blob/master/probaWinGo.ipynb)This notebook trains & compare DL models to predict a probability to win a game of GO from a given set of already played moves. \n",
    "\n",
    "The work in this notebook is based on [L. Simon's file](https://nbviewer.jupyter.org/urls/www.labri.fr/perso/lsimon/IA-M1/TP-Note-ML-GO.ipynb)\n",
    "\n",
    "## First, let's import the database\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "gd0eF6HkxQHf",
    "outputId": "191d0eed-28a2-43b9-bfdc-f94b94fa737a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.4.0\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "import tensorflow as tf\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ozv20eWBvFiq",
    "outputId": "d51a736b-1764-444c-f325-aed960ada1d4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We have 41563 examples with the scores to train, ...\n",
      "We have 1000 examples to score (but for which we don't know the real values)\n"
     ]
    }
   ],
   "source": [
    "def get_raw_data_go(file):\n",
    "    ''' Returns the set of samples from the local file or download it if it does not exists'''\n",
    "    import gzip, os.path\n",
    "    import json\n",
    "\n",
    "    if not os.path.isfile(file):\n",
    "        print(\"File\", file, \"not found, I am downloading it...\\n\", end=\"\")\n",
    "        import urllib.request \n",
    "        urllib.request.urlretrieve (\"https://www.labri.fr/perso/lsimon/IA-M1/\" + file, file)\n",
    "        print(\" Done\")\n",
    "\n",
    "    with gzip.open(file) as fz:\n",
    "        data = json.loads(fz.read().decode(\"utf-8\"))\n",
    "    return data\n",
    "\n",
    "file = \"samples-9x9.json.gz\"\n",
    "file_evaluate = \"positions-to-evaluate-9x9.json.gz\"\n",
    "data = get_raw_data_go(file)\n",
    "data_to_evaluate = get_raw_data_go(file_evaluate)\n",
    "\n",
    "print(\"We have\", len(data),\"examples with the scores to train, ...\")\n",
    "print(\"We have\", len(data_to_evaluate),\"examples to score (but for which we don't know the real values)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "N99O8dLXvFir"
   },
   "source": [
    "## Then, let's explore each entry\n",
    "### First on the data set with results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "HFaNImqJvFis",
    "outputId": "0ad5f63f-7a02-4608-f325-c9bc07572a66"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample 10 \n",
      "\n",
      "Données brutes en format JSON: {'depth': 8, 'list_of_moves': ['C6', 'E7', 'C3', 'C8', 'E5', 'G3', 'B7', 'H7'], 'black_stones': ['B7', 'C6', 'E5', 'C3'], 'white_stones': ['C8', 'E7', 'H7', 'G3'], 'rollouts': 100, 'black_wins': 60, 'black_points': 876.0, 'white_wins': 40, 'white_points': 378.0} \n",
      "\n",
      "The sample was obtained after 8 moves\n",
      "The successive moves were ['C6', 'E7', 'C3', 'C8', 'E5', 'G3', 'B7', 'H7']\n",
      "After these moves and all the captures, there was black stones at the following position ['B7', 'C6', 'E5', 'C3']\n",
      "After these moves and all the captures, there was white stones at the following position ['C8', 'E7', 'H7', 'G3']\n",
      "Number of rollouts (gnugo games played against itself from this position): 100\n",
      "Over these 100 games, black won 60 times with 876.0 total points over all this winning games\n",
      "Over these 100 games, white won 40 times with 378.0 total points over all this winning games\n"
     ]
    }
   ],
   "source": [
    "def summary_of_example(data, sample_nb):\n",
    "    ''' Gives you some insights about a sample number'''\n",
    "    sample = data[sample_nb]\n",
    "    print(\"Sample\", sample_nb,'\\n')\n",
    "    print(\"Données brutes en format JSON:\", sample, '\\n')\n",
    "    print(\"The sample was obtained after\", sample[\"depth\"], \"moves\")\n",
    "    print(\"The successive moves were\", sample[\"list_of_moves\"])\n",
    "    print(\"After these moves and all the captures, there was black stones at the following position\", sample[\"black_stones\"])\n",
    "    print(\"After these moves and all the captures, there was white stones at the following position\", sample[\"white_stones\"])\n",
    "    print(\"Number of rollouts (gnugo games played against itself from this position):\", sample[\"rollouts\"])\n",
    "    print(\"Over these\", sample[\"rollouts\"], \"games, black won\", sample[\"black_wins\"], \"times with\", sample[\"black_points\"], \"total points over all this winning games\")\n",
    "    print(\"Over these\", sample[\"rollouts\"], \"games, white won\", sample[\"white_wins\"], \"times with\", sample[\"white_points\"], \"total points over all this winning games\")\n",
    "\n",
    "    \n",
    "summary_of_example(data,10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IN4MgDCmvFit"
   },
   "source": [
    "### On the data to evaluate, there is less information : "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "StrAXim-vFit",
    "outputId": "e6707d5c-face-4b9b-f4e2-85742974f981"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'depth': 16, 'list_of_moves': ['E6', 'E3', 'C3', 'G6', 'G7', 'C6', 'H7', 'H4', 'D2', 'F6', 'E8', 'C8', 'E5', 'B9', 'E7', 'E2'], 'black_stones': ['E8', 'E7', 'G7', 'H7', 'E6', 'E5', 'C3', 'D2'], 'white_stones': ['B9', 'C8', 'C6', 'F6', 'G6', 'H4', 'E3'], 'rollouts': 100}\n"
     ]
    }
   ],
   "source": [
    "print(data_to_evaluate[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dgSGWW5CvFiu"
   },
   "source": [
    "## Let's try to get a deeper understanding of the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "-13N7oxmvFiv"
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'pandas'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-6fc447902214>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpyplot\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mpandas\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mseaborn\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0msns\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'pandas'"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "3pA8x_shvFiw",
    "outputId": "6944c114-94ac-421a-e35f-f532bf2d2c32"
   },
   "outputs": [],
   "source": [
    "df_data = pd.read_json(file)\n",
    "df_data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 297
    },
    "id": "-I5Htk0-vFix",
    "outputId": "747bed58-037e-4d18-80a0-0df737d5c752"
   },
   "outputs": [],
   "source": [
    "df_data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 560
    },
    "id": "A_O9MZGsvFiy",
    "outputId": "a0b84e39-62cf-42e3-9362-38db9cbae484"
   },
   "outputs": [],
   "source": [
    "def corr_threshold(df,thresh, root_dir=''):\n",
    "    import seaborn as sns\n",
    "    upper = df.corr().where(np.triu(np.ones(df.corr().shape), k=1).astype(np.bool)).abs()\n",
    "    upper = upper[upper>=thresh]\n",
    "    \n",
    "    plt.figure(figsize=(10,5))\n",
    "    hm = sns.heatmap(upper, cmap=\"coolwarm\")\n",
    "    hm.set_xticklabels(hm.get_xticklabels(), rotation=90,fontsize=10)\n",
    "    hm.set_yticklabels(hm.get_yticklabels(), rotation=0,fontsize=10) \n",
    "\n",
    "    plt.savefig(root_dir+'corr_heat.png',transparent=True)\n",
    "    plt.show()\n",
    "    \n",
    "    upper = upper.stack().sort_values(ascending=False)\n",
    "    upper = pd.DataFrame(upper).reset_index()\n",
    "    upper.columns = ['Var 1', 'Var 2', 'correlation']\n",
    "    \n",
    "    index =  np.max([ i for i in range(len(upper['correlation'])) if upper['correlation'][i]>=thresh])\n",
    "    return upper[:index+1]\n",
    "\n",
    "corr_threshold(df_data, 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 312
    },
    "id": "Q8pz1kn6vFiz",
    "outputId": "3c973100-c53d-4c96-ff3e-767fabd5ac8e"
   },
   "outputs": [],
   "source": [
    "# Cumulative Distribution function of the chance of black to win\n",
    "cdf_wins = sorted([sample[\"black_wins\"] for sample in data])\n",
    "plt.figure()\n",
    "plt.plot([x/len(cdf_wins) for x in range(len(cdf_wins))], cdf_wins)\n",
    "plt.title(\"Cumulative Distribution function of the chance of black to win\")\n",
    "plt.xlabel(\"\\% of the samples with a chance of black to win below y\")\n",
    "plt.ylabel(\"Chance of black to win\")\n",
    "print(\"The CDF curve shows that black has more chances to win, globally\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7kLW6tgsvFi0"
   },
   "outputs": [],
   "source": [
    "df_data['range_game'] = 'Beginning'\n",
    "\n",
    "df_data.loc[df_data['depth']>17,'range_game'] = 'Middle'\n",
    "df_data.loc[df_data['depth']>41,'range_game'] = 'End'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 297
    },
    "id": "XwHd7JV4vFi1",
    "outputId": "a531fa14-8cb5-435d-9ad7-3cd2e6cb663d"
   },
   "outputs": [],
   "source": [
    "sns.scatterplot(x='black_wins', y='black_points', \n",
    "                hue='range_game', data=df_data ) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "4hBk-kHCvFi2",
    "outputId": "72c9a929-3a65-4672-f4a1-f0c154071c9f"
   },
   "outputs": [],
   "source": [
    "df_data.groupby(\"range_game\").describe().transpose()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ANjMxs8-vFi3"
   },
   "source": [
    "## Information from the dataset of train :\n",
    "* There is 41563 games \n",
    "* There is almost 65 % of games won by the player black -> hidden bias ? \n",
    "* A given board is awarded a certain number of points as well as the winning porbability\n",
    "* The score of the board and the probability of winning are highly correlated\n",
    "* The depth of the game seems important to predict the probability of winning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fmsi3i7qvFi4"
   },
   "source": [
    "## Let's transform the input data into numpy arrays to feed the NN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qnTYygcIvFi5"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from keras.layers import Activation, Dense\n",
    "\n",
    "def name_to_coord(s):\n",
    "    assert s != \"PASS\"\n",
    "    indexLetters = {'A':0, 'B':1, 'C':2, 'D':3, 'E':4, 'F':5, 'G':6, 'H':7, 'J':8}\n",
    "\n",
    "    col = indexLetters[s[0]]\n",
    "    lin = int(s[1:]) - 1\n",
    "    return col, lin\n",
    "\n",
    " # Vous pouvez utiliser votre propre fonction ici si vous voulez utiliser un autre encodage\n",
    "def json_to_numpy(sample):\n",
    "    to_return = np.zeros((9,9,2))\n",
    "    indices = [\"black_stones\", \"white_stones\"]\n",
    "    for plane, name in enumerate(indices):\n",
    "        for coord_name in sample[name]:\n",
    "            x, y = name_to_coord(coord_name)\n",
    "            to_return[x,y,plane] = 1\n",
    "    return to_return\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "N_JavehcvFi7",
    "outputId": "ed174738-9604-4316-ba7d-73e3baa8f697"
   },
   "outputs": [],
   "source": [
    "samp = 10\n",
    "print('For sample ', samp)\n",
    "print(data[samp])\n",
    "encoded = json_to_numpy(data[samp])\n",
    "\n",
    "print(\"_________________________\\nEncoded shape is\")\n",
    "print(encoded.shape)\n",
    "print(\"The first dimension contains the positioning of the black pieces\")\n",
    "print(encoded[:,:,0])\n",
    "print(\"Black pieces with positions: \", data[10][\"black_stones\"],'\\n')\n",
    "print(\"The second dimension contains the positioning of the white pieces\")\n",
    "print(encoded[:,:,1])\n",
    "print(\"White pieces with positions \", data[10][\"white_stones\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fpTXLoOSvFi8"
   },
   "source": [
    "## We will train a model that predicts the probability of winning \n",
    "To make things easier, we will build a pipeline that processes the json entry, modify it into a numpy array and predicts ***the probability of chance for the black player to win***. \n",
    "\n",
    "To begin with, let's implement a convolutional based NN that process ***only the two sets of boards*** as a whole information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "R1_5drlSvFi8"
   },
   "outputs": [],
   "source": [
    "def get_dataset(data, random_state = 42, test_size = 0.33) : \n",
    "  X = []\n",
    "  y = []\n",
    "  for d in data:\n",
    "    X.append(json_to_numpy(d))\n",
    "    y.append(d[\"black_wins\"] / d[\"rollouts\"])\n",
    "\n",
    "  X = np.array(X)\n",
    "  y = np.array(y)\n",
    "  X_train, X_test, y_train, y_test = train_test_split(X, y, test_size= test_size, random_state= random_state)\n",
    "  print('Each entry is of shape : {}\\nThere is {} samples in the train set and {} in the test'.format( X_train[0].shape, X_train.shape[0], X_test.shape[0] ))\n",
    "  print('Here is a sample : \\nX[0] :',X_train[0][0] , '\\nX[1] :', X_train[0][1] , '\\n y :',y_train[0])\n",
    "  return X_train, X_test, y_train, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "RNYtYpbhvd4i",
    "outputId": "fce42b2f-2070-4a1e-eac0-3b0cda433d3c"
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = get_dataset(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "zweg1px0yje8",
    "outputId": "955ec192-d429-4f78-ffa8-13ef9d944041"
   },
   "outputs": [],
   "source": [
    "from keras.layers import Activation, Dense, Dropout\n",
    "\n",
    "model = tf.keras.models.Sequential()\n",
    "model.add(tf.keras.layers.InputLayer(input_shape=(9,9,2)))\n",
    "model.add(tf.keras.layers.Conv2D(filters=16,kernel_size=3,padding='same'))\n",
    "model.add(tf.keras.layers.Conv2D(filters=16,kernel_size=3,padding='same'))\n",
    "model.add(tf.keras.layers.Dense(50, activation='relu', kernel_initializer='normal')) #64 = neurone, kernel_n\n",
    "model.add(tf.keras.layers.Dense(50, activation='relu', kernel_initializer='normal')) #64 = neurone, kernel_n\n",
    "model.add(Dropout(0.5))\n",
    "model.add(tf.keras.layers.Dense(50, activation='relu', kernel_initializer='normal')) #64 = neurone, kernel_n\n",
    "\n",
    "\n",
    "\n",
    "model.add(tf.keras.layers.Flatten())\n",
    "model.add(tf.keras.layers.Dense(1,activation='sigmoid'))\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6Zu2fMiEzex3",
    "outputId": "344c7bed-4f9f-4e79-94ce-41823af67240"
   },
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam',loss=tf.keras.losses.MeanSquaredError())\n",
    "\n",
    "\n",
    "callbacks = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience = 20, restore_best_weights= True)\n",
    "\n",
    "history = model.fit(X_train, y_train, \n",
    "                    validation_data = (X_test, y_test), \n",
    "\n",
    "                    callbacks = callbacks, \n",
    "                    epochs=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 295
    },
    "id": "C4hD-eAl05C8",
    "outputId": "278a3367-7af4-4119-e194-6d3614120440"
   },
   "outputs": [],
   "source": [
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'val'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "TymgCc_QGm5x",
    "outputId": "a6202a27-690b-47e6-b45f-f5501beaa54f"
   },
   "outputs": [],
   "source": [
    "samp = 5\n",
    "\n",
    "model.predict(X_test[samp:samp+5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "StESLyv4JOp2",
    "outputId": "52ab3c44-d220-4352-9070-1c4ac1c79744"
   },
   "outputs": [],
   "source": [
    "y_test[samp:samp+5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "qqFyGMvkxsqs",
    "outputId": "7225e9f6-e120-4565-c275-cb829e7b35a2"
   },
   "outputs": [],
   "source": [
    "def position_predict(description):\n",
    "    # Cette méthode doit prendre une description de partie (un élément de l'ensemble \n",
    "    # des exemples donnés en format JSON) et va produire la prédiction de victoire\n",
    "\n",
    "    # ... Votre tambouille interne pour placer les pierres comme il faut dans votre structure de données\n",
    "    # et appeler votre modèle Keras (typiquement avec model.predict())\n",
    "    # Si vous utilisez la fonction de base donéee ci-dessus, cela pourra être\n",
    "    input = json_to_numpy(description)\n",
    " \n",
    "    # input est ici un seul exemple. Votre modèle demandant un ensemble d'exemples\n",
    "    # il faudra étendre ses dimensions pour que model recoivent un tenseur contenant\n",
    "    # un seul exemple : on utilse expand_dims pour dire qu'au lieu d'avoir x \n",
    "    # on a en fait [x]\n",
    "    # Si (comme on l'a fait) on a un X qui a les dimensions (9,9,2)\n",
    "    #  alors on aura un tenseur aux dimensions (1,9,9,2)\n",
    "    input = np.expand_dims(input, axis=0)\n",
    "  \n",
    "    prediction = model.predict(input) # Ne marchera que si model est correctement defini\n",
    "    \n",
    "    return prediction[0] # De même ici on réduit la dimension de sortie\n",
    "\n",
    "# Par exemple, nous pourrons appeler votre prédiction ainsi\n",
    "\n",
    "print(\"Prediction this sample:\")\n",
    "summary_of_example(data, 10)\n",
    "print()\n",
    "prediction = position_predict(data[10])\n",
    "print(\"You predicted\", prediction, \"and the actual target was\", data[10][\"black_wins\"]/data[10][\"rollouts\"])\n",
    "\n",
    "# Ainsi, pour le rendu, en admettant que newdata soit le fichier json contenant\n",
    "# les plateaux à prédire vous pourrez construire le fichier resultat ainsi\n",
    "# vérifiez tout de même que la sortie est ok avant de la soumettre\n",
    "\n",
    "def create_result_file(newdata):\n",
    "    ''' Exemple de méthode permettant de générer le fichier de resultats demandés. '''\n",
    "    resultat  = [position_predict(d[\"black_stones\"], d[\"white_stones\"]) for d in newdata]\n",
    "    with open(\"my_predictions.txt\", \"w\") as f:\n",
    "         for p in resultat:\n",
    "            f.write(str(p)+\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "cbcTDADDy7Rc",
    "outputId": "61e4c41c-ff53-4809-9154-003b1f1c1e44"
   },
   "outputs": [],
   "source": [
    "def percentEcart(X_test, y_test, nbTest):\n",
    "  result = model.predict(X_test[0:nbTest])\n",
    "  cinq = 0\n",
    "  dix = 0\n",
    "  vingt = 0\n",
    "  tcinq = 0\n",
    "  cinquante = 0\n",
    "  for i in range(nbTest):\n",
    "    ecart = abs(y_test[i]-result[i])\n",
    "    #print(ecart)\n",
    "    if ecart <= 0.05:\n",
    "      cinq +=1\n",
    "    if ecart <= 0.1:\n",
    "      dix +=1\n",
    "    if ecart <= 0.2:\n",
    "      vingt +=1\n",
    "    if ecart <= 0.35:\n",
    "      tcinq +=1\n",
    "    if ecart <= 0.5:\n",
    "      cinquante +=1\n",
    "    #print(\"L'ecart pour la prevision numero \",i,\" est de : \",ecart)\n",
    "  print(\"Pourcentage de prevision moins de 5% d'erreur : \",cinq/nbTest)\n",
    "  print(\"Pourcentage de prevision moins de 10% d'erreur : \",dix/nbTest)\n",
    "  print(\"Pourcentage de prevision moins de 20% d'erreur : \",vingt/nbTest)\n",
    "  print(\"Pourcentage de prevision moins de 35% d'erreur : \",tcinq/nbTest)\n",
    "  print(\"Pourcentage de prevision moins de 50% d'erreur : \",cinquante/nbTest)\n",
    "\n",
    "percentEcart(X_test, y_test, 500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "haCzxW5BJRML"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "name": "probaWinGo.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
