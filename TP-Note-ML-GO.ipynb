{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "48P2aoXicD4-"
   },
   "source": [
    "# Apprenez une heuristique pour le Go\n",
    "\n",
    "Dans ce TP noté, vous devrez déployer des methodes d'apprentissage automatique permettant d'évaluer la qualité de plateaux de GO.\n",
    "\n",
    "Pour cela, vous disposerez de 41563 exemples de plateau de Go, tous générés par gnugo après quelques coups contre lui même avec un niveau de difficulté de 0. Par chaque plateau, nous avons lancé 100 matchs de gnugo contre lui même, toujours avec un niveau 0, et compté le nombre de victoires de noir et de blanc depuis ce plateau.\n",
    "\n",
    "A noter, chaque \"rollout\" (un rollout et un déroulement possible du match depuis le plateau de référence) correspond à des mouvements choisis aléatoirement parmis les 10 meilleurs mouvements possibles, en biasant le choix aléatoire par la qualité prédite du mouvement par gnugo (les meilleurs mouvements ont une plus forte probabilité d'être tirés).\n",
    "\n",
    "Les données dont vous disposez sont brutes. Ce sera à vous de proposer un format adéquat pour utiliser ces données en entrée de votre réseau neuronal. \n",
    "\n",
    "## Comment sera évalué votre modèle ?\n",
    "\n",
    "Nous vous fournirons 6h avant la date de rendu un nouveau fichier contenant 1000 nouveaux exemples, qui ne contiendront pas les champs `black_wins`, `white_wins`, `black_points` et `white_points`. Vous devrez laisser, dans votre dépot de projet un fichier texte nommé `my_predictions.txt` ayant une prédiction par ligne (un simple flottant) qui donnera, dans le même ordre de la liste des exemples les scores que vous prédisez pour chacune des entrées du fichier que nous vous aurons donné. Il faudra laisser, dans votre feuille notebook (voir tout en dessous) la cellule Python qui aura créé ce fichier, pour que l'on puisse éventuellement refaire vos prédictions.\n",
    "\n",
    "### Le rendu attendu de ce TP\n",
    "\n",
    "Bien entendu, vous nous rendrez également votre feuille jupyter **sous deux formats**, à la fois le fichier `.ipynb` et le fichier `.html` nous permettant de lire ce que vous avez fait, sans forcément relancer la feuille. Nous prendrons en compte les résultats obtenus sur les prédictions mais aussi le contenu de vos notebooks jupyter. Il faudra donc donner **trois fichiers** :\n",
    " les deux contenant votre notebook et celui contenant vos prédictions.\n",
    "\n",
    "### Comment sera noté ce TP ?\n",
    "\n",
    "Il s'agit \"seulement\" d'un TP noté, donc il ne faudra pas y passer trop de temps. Nous attendons des prédictions correctes mais surtout des choix justifiés dans la feuille. Votre feuille notebook sera le plus important pour la notation (n'hésitez pas à mettre des cellules de texte pour expliquer pourquoi vous avez été amenés à faire certains choix). Ainsi, il serait bien d'avoir, par exemple, les données (graphiques ou autre) qui permettent de comprendre comment vous avez évité l'overfitting.\n",
    "\n",
    "Le fichier de vos prédictions sera évalué en se basant sur la qualité de vos prédictions. Nous mesurerons par exemple le nombre d'exemples dont votre prédiction donnera la bonne valeur à 5%, 10%, 20%, 35%, 50% pour estimer sa qualité. Nous pourrons également prendre en compte une mesure basée simplement sur la distance de vos prédictions aux vraies valeurs.\n",
    "\n",
    "\n",
    "## Mise en route !\n",
    "\n",
    "Voyons  comment lire les données !\n",
    "A la fin vous aurez\n",
    "- `data` qui contiendra les données sur lesquelles faire votre apprentissage (ces données contiennent la valeur qu'il faut prévoir pour entrainer votre réseau)\n",
    "- `data_to_evaluate` qui contiendra les données sur lesquelles faire vos prédictions. Vous n'avez pas pour ces valeurs les vraies prédictions ! Il faudra faire au mieux !\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "TlW_qQYCcD4_",
    "outputId": "908ea9ea-d900-41dd-8034-5514a04ed7b4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We have 41563 examples with the scores to train, ...\n",
      "We have 1000 examples to score (but for which we don't know the real values)\n"
     ]
    }
   ],
   "source": [
    "# Import du fichier d'exemples\n",
    "\n",
    "def get_raw_data_go(file):\n",
    "    ''' Returns the set of samples from the local file or download it if it does not exists'''\n",
    "    import gzip, os.path\n",
    "    import json\n",
    "\n",
    "    if not os.path.isfile(file):\n",
    "        print(\"File\", file, \"not found, I am downloading it...\", end=\"\")\n",
    "        import urllib.request \n",
    "        urllib.request.urlretrieve (\"https://www.labri.fr/perso/lsimon/IA-M1/\" + file, file)\n",
    "        print(\" Done\")\n",
    "\n",
    "    with gzip.open(file) as fz:\n",
    "        data = json.loads(fz.read().decode(\"utf-8\"))\n",
    "    return data\n",
    "\n",
    "data = get_raw_data_go(\"samples-9x9.json.gz\")\n",
    "data_to_evaluate = get_raw_data_go(\"positions-to-evaluate-9x9.json.gz\")\n",
    "\n",
    "print(\"We have\", len(data),\"examples with the scores to train, ...\")\n",
    "print(\"We have\", len(data_to_evaluate),\"examples to score (but for which we don't know the real values)\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EgrGAXC5cD5B"
   },
   "source": [
    "## Compréhension des données de chaque entrée\n",
    "\n",
    "Voici une description de chaque exemple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "fmOoP_LccD5B",
    "outputId": "a49287d9-29f5-4212-90a0-1c814ad7868f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exemple sur les données qui ont les résultats visés\n",
      "Sample 10\n",
      "\n",
      "Données brutes en format JSON: {'depth': 8, 'list_of_moves': ['C6', 'E7', 'C3', 'C8', 'E5', 'G3', 'B7', 'H7'], 'black_stones': ['B7', 'C6', 'E5', 'C3'], 'white_stones': ['C8', 'E7', 'H7', 'G3'], 'rollouts': 100, 'black_wins': 60, 'black_points': 876.0, 'white_wins': 40, 'white_points': 378.0}\n",
      "\n",
      "The sample was obtained after 8 moves\n",
      "The successive moves were ['C6', 'E7', 'C3', 'C8', 'E5', 'G3', 'B7', 'H7']\n",
      "After these moves and all the captures, there was black stones at the following position ['B7', 'C6', 'E5', 'C3']\n",
      "After these moves and all the captures, there was white stones at the following position ['C8', 'E7', 'H7', 'G3']\n",
      "Number of rollouts (gnugo games played against itself from this position): 100\n",
      "Over these 100 games, black won 60 times with 876.0 total points over all this winning games\n",
      "Over these 100 games, white won 40 times with 378.0 total points over all this winning games\n",
      "\n",
      "Remarquez que, sur les données à prédire, il manque des valeurs :) :\n",
      "{'depth': 16, 'list_of_moves': ['E6', 'E3', 'C3', 'G6', 'G7', 'C6', 'H7', 'H4', 'D2', 'F6', 'E8', 'C8', 'E5', 'B9', 'E7', 'E2'], 'black_stones': ['E8', 'E7', 'G7', 'H7', 'E6', 'E5', 'C3', 'D2'], 'white_stones': ['B9', 'C8', 'C6', 'F6', 'G6', 'H4', 'E3'], 'rollouts': 100}\n"
     ]
    }
   ],
   "source": [
    "def summary_of_example(data, sample_nb):\n",
    "    ''' Gives you some insights about a sample number'''\n",
    "    sample = data[sample_nb]\n",
    "    print(\"Sample\", sample_nb)\n",
    "    print()\n",
    "    print(\"Données brutes en format JSON:\", sample)\n",
    "    print()\n",
    "    print(\"The sample was obtained after\", sample[\"depth\"], \"moves\")\n",
    "    print(\"The successive moves were\", sample[\"list_of_moves\"])\n",
    "    print(\"After these moves and all the captures, there was black stones at the following position\", sample[\"black_stones\"])\n",
    "    print(\"After these moves and all the captures, there was white stones at the following position\", sample[\"white_stones\"])\n",
    "    print(\"Number of rollouts (gnugo games played against itself from this position):\", sample[\"rollouts\"])\n",
    "    print(\"Over these\", sample[\"rollouts\"], \"games, black won\", sample[\"black_wins\"], \"times with\", sample[\"black_points\"], \"total points over all this winning games\")\n",
    "    print(\"Over these\", sample[\"rollouts\"], \"games, white won\", sample[\"white_wins\"], \"times with\", sample[\"white_points\"], \"total points over all this winning games\")\n",
    "\n",
    "print(\"Exemple sur les données qui ont les résultats visés\")\n",
    "summary_of_example(data,10)\n",
    "\n",
    "print()\n",
    "print(\"Remarquez que, sur les données à prédire, il manque des valeurs :) :\")\n",
    "print(data_to_evaluate[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "rn2Rt8xkcD5B",
    "outputId": "ded0e1ee-9b3b-47f7-eea2-8f379b67d2ec"
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'matplotlib'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-059be9a53cb0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmagic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'matplotlib inline'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpyplot\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtitle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Relationship between the depth of the board and the chance for black to win\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0msample\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"black_wins\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0msample\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0msample\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"depth\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0msample\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'.'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3/dist-packages/IPython/core/interactiveshell.py\u001b[0m in \u001b[0;36mmagic\u001b[0;34m(self, arg_s)\u001b[0m\n\u001b[1;32m   2158\u001b[0m         \u001b[0mmagic_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmagic_arg_s\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0marg_s\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpartition\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m' '\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2159\u001b[0m         \u001b[0mmagic_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmagic_name\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlstrip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprefilter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mESC_MAGIC\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2160\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_line_magic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmagic_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmagic_arg_s\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2161\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2162\u001b[0m     \u001b[0;31m#-------------------------------------------------------------------------\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3/dist-packages/IPython/core/interactiveshell.py\u001b[0m in \u001b[0;36mrun_line_magic\u001b[0;34m(self, magic_name, line)\u001b[0m\n\u001b[1;32m   2079\u001b[0m                 \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'local_ns'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getframe\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstack_depth\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf_locals\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2080\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuiltin_trap\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2081\u001b[0;31m                 \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2082\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2083\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<decorator-gen-105>\u001b[0m in \u001b[0;36mmatplotlib\u001b[0;34m(self, line)\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3/dist-packages/IPython/core/magic.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(f, *a, **k)\u001b[0m\n\u001b[1;32m    186\u001b[0m     \u001b[0;31m# but it's overkill for just that one bit of state.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    187\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mmagic_deco\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 188\u001b[0;31m         \u001b[0mcall\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    189\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    190\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcallable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3/dist-packages/IPython/core/magics/pylab.py\u001b[0m in \u001b[0;36mmatplotlib\u001b[0;34m(self, line)\u001b[0m\n\u001b[1;32m     98\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Available matplotlib backends: %s\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mbackends_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     99\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 100\u001b[0;31m             \u001b[0mgui\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbackend\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshell\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menable_matplotlib\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgui\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    101\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_show_matplotlib_backend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgui\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbackend\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    102\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3/dist-packages/IPython/core/interactiveshell.py\u001b[0m in \u001b[0;36menable_matplotlib\u001b[0;34m(self, gui)\u001b[0m\n\u001b[1;32m   2936\u001b[0m         \"\"\"\n\u001b[1;32m   2937\u001b[0m         \u001b[0;32mfrom\u001b[0m \u001b[0mIPython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcore\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpylabtools\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mpt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2938\u001b[0;31m         \u001b[0mgui\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbackend\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfind_gui_and_backend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgui\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpylab_gui_select\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2939\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2940\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mgui\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;34m'inline'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3/dist-packages/IPython/core/pylabtools.py\u001b[0m in \u001b[0;36mfind_gui_and_backend\u001b[0;34m(gui, gui_select)\u001b[0m\n\u001b[1;32m    271\u001b[0m     \"\"\"\n\u001b[1;32m    272\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 273\u001b[0;31m     \u001b[0;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    274\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    275\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mgui\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mgui\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;34m'auto'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'matplotlib'"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.title(\"Relationship between the depth of the board and the chance for black to win\")\n",
    "plt.plot([sample[\"black_wins\"] for sample in data],[sample[\"depth\"] for sample in data], '.')\n",
    "plt.xlabel(\"black wins (percentage)\")\n",
    "plt.ylabel(\"depth of the game\")\n",
    "\n",
    "\n",
    "# Cumulative Distribution function of the chance of black to win\n",
    "cdf_wins = sorted([sample[\"black_wins\"] for sample in data])\n",
    "plt.figure()\n",
    "plt.plot([x/len(cdf_wins) for x in range(len(cdf_wins))], cdf_wins)\n",
    "plt.title(\"Cumulative Distribution function of the chance of black to win\")\n",
    "plt.xlabel(\"\\% of the samples with a chance of black to win below y\")\n",
    "plt.ylabel(\"Chance of black to win\")\n",
    "print(\"The CDF curve shows that black has more chances to win, globally\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hf2M2XxkcD5B"
   },
   "source": [
    "# First steps: transform all the data into numpy arrays to feed your neural network\n",
    "\n",
    "(désolé je viens de me rendre compte que je viens de passer en anglais :))\n",
    "\n",
    "Advices:\n",
    "- do not use only a single 9x9 matrix as input. Use at least two planes to encode the board. One plane for black and one plane for white (typically with a 1 if there is a black stone for the first plane and with a 1 if there is a white stone for the second plane). The dimension of an input should be at least `[9,9,2]` as it is proposed in the example below. Of course you can use a more interesting encoding of the board into tensors.\n",
    "- if you have time, you could consider to enrich your dataset with all symmetries and rotations. You should be able to multiply the number of samples to consider: any rotation of the board should have the same score, right?\n",
    "- what should happen on the score if you switch the colors? To know which player has to play next, you can check, for a sample, the parity of the length of the list `data[i][\"list_of_moves\"]` (an odd length list would mean that white is the next player. An even length list means that black has to play).\n",
    "- work on enlarging and preparing your data only once. Once all you input data is setup as a big Numpy matrix, you may want to save it for speeding up everything. You can use, for instance `numpy.rot90()` and `numpy.flipud()` to generate all the symmetries\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "mPw4QA0AcD5B",
    "outputId": "80ec0a7d-6286-4606-c9a7-9cc7dd2791ba"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Par exemple voici ce que va donner notre encodage pour l'exemple 10:\n",
      "{'depth': 8, 'list_of_moves': ['C6', 'E7', 'C3', 'C8', 'E5', 'G3', 'B7', 'H7'], 'black_stones': ['B7', 'C6', 'E5', 'C3'], 'white_stones': ['C8', 'E7', 'H7', 'G3'], 'rollouts': 100, 'black_wins': 60, 'black_points': 876.0, 'white_wins': 40, 'white_points': 378.0}\n",
      "La matrice résultat est de dimension\n",
      "(9, 9, 2)\n",
      "Plan 0 du tenseur : contient les pieces contenant une pierre noire sur l'exemple 10\n",
      "[[0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
      " [0. 0. 1. 0. 0. 1. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 1. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "Les positions des pierres sont  ['B7', 'C6', 'E5', 'C3']\n",
      "\n",
      "Plan 1 du tenseur : contient les pieces contenant une pierre blanche sur l'exemple 10\n",
      "[[0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 1. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 1. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "Les positions des pierres sont  ['C8', 'E7', 'H7', 'G3']\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "def name_to_coord(s):\n",
    "    assert s != \"PASS\"\n",
    "    indexLetters = {'A':0, 'B':1, 'C':2, 'D':3, 'E':4, 'F':5, 'G':6, 'H':7, 'J':8}\n",
    "\n",
    "    col = indexLetters[s[0]]\n",
    "    lin = int(s[1:]) - 1\n",
    "    return col, lin\n",
    "\n",
    " # Vous pouvez utiliser votre propre fonction ici si vous voulez utiliser un autre encodage\n",
    "def json_to_numpy(sample):\n",
    "  to_return = np.zeros((9,9,2))\n",
    "  indices = [\"black_stones\", \"white_stones\"]\n",
    "  for plane, name in enumerate(indices):\n",
    "    for coord_name in sample[name]:\n",
    "      x, y = name_to_coord(coord_name)\n",
    "      to_return[x,y,plane] = 1\n",
    "  return to_return\n",
    "\n",
    "print(\"Par exemple voici ce que va donner notre encodage pour l'exemple 10:\")\n",
    "print(data[10])\n",
    "encoded = json_to_numpy(data[10])\n",
    "\n",
    "print(\"La matrice résultat est de dimension\")\n",
    "print(encoded.shape)\n",
    "print(\"Plan 0 du tenseur : contient les pieces contenant une pierre noire sur l'exemple 10\")\n",
    "print(encoded[:,:,0])\n",
    "print(\"Les positions des pierres sont \", data[10][\"black_stones\"])\n",
    "print()\n",
    "print(\"Plan 1 du tenseur : contient les pieces contenant une pierre blanche sur l'exemple 10\")\n",
    "print(encoded[:,:,1])\n",
    "print(\"Les positions des pierres sont \", data[10][\"white_stones\"])\n",
    "\n",
    "print()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "c4jGlB-PcD5B"
   },
   "source": [
    "## Données en entrée et en sortie de votre modèle final\n",
    "\n",
    "Même si en interne, votre modèle va manipuler des tenseurs en numpy, vous devrez construire une boite noire qui prendra en entrée un élément json décrivant les coordonnées des pierres noires et blanche et **donnera le pourcentage de chance pour noir** de gagner depuis cette position. On ne cherche pas à prédire la moyenne des scores, mais seulement le pourcentage de victoire (donc un flottant entre 0 et 1) !\n",
    "\n",
    "Ainsi, pour l'exemple `i` :\n",
    "- Vous prendez en entree `data[i]`\n",
    "- Vous devrez prédire simplement `data[i][\"black_wins\"]/data[i][\"rollouts\"]`\n",
    "\n",
    "Encore une fois, **attention** : en interne, il faudra absolument construire vos données formattées en matrices numpy pour faire votre entrainement. On vous demande juste ici d'écrire comment vous faites ces transformations, pour comprendre ce que vous avez décidé de mettre en entrée du réseau.\n",
    "\n",
    "### Exemple de cellule permettant de genérer le fichier qu'il faudra donner\n",
    "\n",
    "Voici le modèle de la fonction qui pourra être appelée, au final (Attention, ce n'est qu'un exemple, vous pourrez par exemple avoir une fonction qui prend plus de paramètres en entrée pour produire votre prédiction):\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "NnkjKg1ncD5B",
    "outputId": "a6f7d3b4-2fbc-4622-9699-68b778e094e9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction this sample:\n",
      "Sample 10\n",
      "\n",
      "Données brutes en format JSON: {'depth': 8, 'list_of_moves': ['C6', 'E7', 'C3', 'C8', 'E5', 'G3', 'B7', 'H7'], 'black_stones': ['B7', 'C6', 'E5', 'C3'], 'white_stones': ['C8', 'E7', 'H7', 'G3'], 'rollouts': 100, 'black_wins': 60, 'black_points': 876.0, 'white_wins': 40, 'white_points': 378.0}\n",
      "\n",
      "The sample was obtained after 8 moves\n",
      "The successive moves were ['C6', 'E7', 'C3', 'C8', 'E5', 'G3', 'B7', 'H7']\n",
      "After these moves and all the captures, there was black stones at the following position ['B7', 'C6', 'E5', 'C3']\n",
      "After these moves and all the captures, there was white stones at the following position ['C8', 'E7', 'H7', 'G3']\n",
      "Number of rollouts (gnugo games played against itself from this position): 100\n",
      "Over these 100 games, black won 60 times with 876.0 total points over all this winning games\n",
      "Over these 100 games, white won 40 times with 378.0 total points over all this winning games\n",
      "\n",
      "You predicted [0.5253773] and the actual target was 0.6\n"
     ]
    }
   ],
   "source": [
    "def position_predict(description):\n",
    "    # Cette méthode doit prendre une description de partie (un élément de l'ensemble \n",
    "    # des exemples donnés en format JSON) et va produire la prédiction de victoire\n",
    "\n",
    "    # ... Votre tambouille interne pour placer les pierres comme il faut dans votre structure de données\n",
    "    # et appeler votre modèle Keras (typiquement avec model.predict())\n",
    "    # Si vous utilisez la fonction de base donéee ci-dessus, cela pourra être\n",
    "    input = json_to_numpy(description)\n",
    " \n",
    "    # input est ici un seul exemple. Votre modèle demandant un ensemble d'exemples\n",
    "    # il faudra étendre ses dimensions pour que model recoivent un tenseur contenant\n",
    "    # un seul exemple : on utilse expand_dims pour dire qu'au lieu d'avoir x \n",
    "    # on a en fait [x]\n",
    "    # Si (comme on l'a fait) on a un X qui a les dimensions (9,9,2)\n",
    "    #  alors on aura un tenseur aux dimensions (1,9,9,2)\n",
    "    input = np.expand_dims(input, axis=0)\n",
    "  \n",
    "    prediction = model.predict(input) # Ne marchera que si model est correctement defini\n",
    "    \n",
    "    return prediction[0] # De même ici on réduit la dimension de sortie\n",
    "\n",
    "# Par exemple, nous pourrons appeler votre prédiction ainsi\n",
    "\n",
    "print(\"Prediction this sample:\")\n",
    "summary_of_example(data, 10)\n",
    "print()\n",
    "prediction = position_predict(data[10])\n",
    "print(\"You predicted\", prediction, \"and the actual target was\", data[10][\"black_wins\"]/data[10][\"rollouts\"])\n",
    "\n",
    "# Ainsi, pour le rendu, en admettant que newdata soit le fichier json contenant\n",
    "# les plateaux à prédire vous pourrez construire le fichier resultat ainsi\n",
    "# vérifiez tout de même que la sortie est ok avant de la soumettre\n",
    "\n",
    "def create_result_file(newdata):\n",
    "    ''' Exemple de méthode permettant de générer le fichier de resultats demandés. '''\n",
    "    resultat  = [position_predict(d[\"black_stones\"], d[\"white_stones\"]) for d in newdata]\n",
    "    with open(\"my_predictions.txt\", \"w\") as f:\n",
    "         for p in resultat:\n",
    "            f.write(str(p)+\"\\n\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GryB1BkqcD5B"
   },
   "source": [
    "# Second steps: build your neural network and train it\n",
    "\n",
    "Don't forget to check overfitting, ...\n",
    "\n",
    "*advices* :\n",
    "- you need to test Dense and Conv2D layers (the best models may contain convolution layers=\n",
    "- if you use convolution layers, be sure not to downsize your board. Applying a filter should keep the original size of the board (9x9), otherwise you would somehow forget the stones on the borders\n",
    "- you will use like 33% of your input sample for validation. However, the final goal is to score new data that will be given in addition to the actual data. So, you should use the 33% splitting rule to set up your network architecture and, once you fixed it, you should train your final model on the whole set of data, crossing your fingers that it will generalize well.\n",
    "- Warning: if you launch the fit function from keras more than once, it will not reset the weights and the biases of your neural network. It's good news because you can add more and more epochs to your model, but be careful about the training/test sets: each time you call fit() with validation_split set up to something like 0.33, it will choose a **new** partition of the samples. So you are breaking your validation/training partition! We advice you to use the `sklearn.model_selection.train_test_split()` method to split the set of examples just once and then use the parameter `validation_data` in the call for `fit()`.  Thus you will be able to call it multiple time.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "jbwhO9a_cD5C"
   },
   "outputs": [],
   "source": [
    "import tensorflow.keras\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, Activation, Flatten\n",
    "from tensorflow.keras.layers import Conv2D, BatchNormalization\n",
    "import tensorflow.keras.optimizers as optimizers\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "# A vous de remplir\n",
    "# model.add(...)\n",
    "# ...\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PemhaY7YkOpw"
   },
   "source": [
    "# Now we can build our sets for training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "o9Hipn-fkSTR",
    "outputId": "942faf67-2cb5-451e-bdf7-ce4ec0e52683"
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'np' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-7b4ddd9479a8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mseed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m12345\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# A changer pour ne pas mélanger toujours pareil\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'np' is not defined"
     ]
    }
   ],
   "source": [
    "# Ce bout de code produit (X, Y)\n",
    "# Pour retrouver vos habitudes\n",
    "\n",
    "\n",
    "np.random.seed(12345)  # A changer pour ne pas mélanger toujours pareil\n",
    "\n",
    "X = []\n",
    "Y = []\n",
    "for d in data:\n",
    "  X.append(json_to_numpy(d))\n",
    "  Y.append(d[\"black_wins\"] / d[\"rollouts\"])\n",
    "\n",
    "X = np.array(X)\n",
    "Y = np.array(Y)\n",
    "\n",
    "\n",
    "print(X.shape)\n",
    "print(Y.shape)\n",
    "\n",
    "\n",
    "X_to_predict = []\n",
    "for d in data_to_evaluate:\n",
    "  X_to_predict.append(json_to_numpy(d))\n",
    "X_to_predict = np.array(X_to_predict)\n",
    "\n",
    "print(\"Et voici les 1000 exemples à prédire, prêts à passer dans votre réseau\")\n",
    "print(X_to_predict.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gZ8E7eNEcD5C"
   },
   "source": [
    "# Last step\n",
    "\n",
    "Prepare your model to predict the set of new data to predict, and predict the file with the 1000 examples to predict!\n",
    "\n",
    "(may be you would like to express, when guessing the percentage of wins for blacks, that it should reflect the fact that this score should be the same for all the symmetries you considered)..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "3-AZrYhXcD5C"
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-3ba6097a7fa4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'AREMPLIR'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'AREMPLIR'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# A renseigner correctement\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m# Plutot que X_train, Y_train et X_test, Y_test on passe tous les exemples\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# et on demande à keras de découper en deux ensembles (training et test)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m# grâce au paramètre validation_split\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'model' is not defined"
     ]
    }
   ],
   "source": [
    "model.compile(loss='AREMPLIR', optimizer='AREMPLIR') # A renseigner correctement\n",
    "\n",
    "# Plutot que X_train, Y_train et X_test, Y_test on passe tous les exemples\n",
    "# et on demande à keras de découper en deux ensembles (training et test)\n",
    "# grâce au paramètre validation_split\n",
    "# Bien entendu il faudra plus de 20 epochs, mais c'est à vous de modifier cela !\n",
    "model.fit(X, Y, epochs=20, validation_split=0.33)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "TP-Note-ML-GO.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
